{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\n",
    "baby_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First five records in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "baby_df.review = baby_df.review.apply(lambda x: remove_punctuation((str(x))))\n",
    "\n",
    "#short test: \n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\n",
    "remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row that was with punctuations now is same as string with same sentence and without punctuations, so it works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b)\n",
    "\n",
    "baby_df = baby_df.fillna(\"\")\n",
    "\n",
    "#short test:\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\n",
    "baby_df = baby_df.drop(baby_df[baby_df.rating == 3].index)\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"] == 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of ratings which equals 3 is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d) \n",
    "def set_val(rating):\n",
    "    if rating <= 2:\n",
    "        return -1\n",
    "    if rating >= 4:\n",
    "        return 1\n",
    "\n",
    "baby_df.rating = baby_df.rating.apply(lambda x: set_val(x))\n",
    "#short test:\n",
    "sum(baby_df[\"rating\"]**2 != 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum of ratings different than 1 is 0, there are no negative ratings so no ratings where added, thus function works properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "reviews_train_example = [\"We like apples\",\n",
    "                   \"We hate oranges\",\n",
    "                   \"I adore bananas\",\n",
    "                   \"We like like apples and oranges\",\n",
    "                   \"They dislike bananas\"]\n",
    "\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_train_example.todense())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adore', 'and', 'apples', 'bananas', 'dislike', 'hate', 'like', 'oranges', 'they', 'we']\n",
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "reviews_test_example = [\"They like bananas\",\n",
    "                   \"We hate oranges bananas and apples\",\n",
    "                   \"We love bananas\"] #New word!\n",
    "\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\n",
    "start = time.time()\n",
    "\n",
    "review_train, review_test, rating_train, rating_test = train_test_split(baby_df.review,baby_df.rating, test_size=0.3, random_state=45)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into training and test sets in ratio 7 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(baby_df.review)\n",
    "\n",
    "review_train_V = vectorizer.transform(review_train)\n",
    "review_test_V = vectorizer.transform(review_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting vectorizer to review and then do the data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\n",
    "model = LogisticRegression()\n",
    "model.fit(review_train_V, rating_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model of logistic regression and fitting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\n",
    "coefs = model.coef_[0]\n",
    "d = {\"Coef\": coefs, \"Words\": vectorizer.get_feature_names()}\n",
    "words_table = pd.DataFrame(d)\n",
    "\n",
    "#hint: model.coef_, vectorizer.get_feature_names()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dataframe with coefficients and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>2.396217</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46753</th>\n",
       "      <td>2.311483</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93841</th>\n",
       "      <td>2.298750</td>\n",
       "      <td>pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55107</th>\n",
       "      <td>2.120888</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60684</th>\n",
       "      <td>2.074559</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11747</th>\n",
       "      <td>2.054904</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139488</th>\n",
       "      <td>2.047722</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106408</th>\n",
       "      <td>1.880788</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31732</th>\n",
       "      <td>1.797631</td>\n",
       "      <td>complaint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46671</th>\n",
       "      <td>1.777552</td>\n",
       "      <td>exactly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coef      Words\n",
       "15420   2.396217    awesome\n",
       "46753   2.311483  excellent\n",
       "93841   2.298750    pleased\n",
       "55107   2.120888       glad\n",
       "60684   2.074559     highly\n",
       "11747   2.054904    amazing\n",
       "139488  2.047722      worry\n",
       "106408  1.880788  satisfied\n",
       "31732   1.797631  complaint\n",
       "46671   1.777552    exactly"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_table.sort_values(by=\"Coef\", ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten most positive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139538</th>\n",
       "      <td>-3.184703</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39961</th>\n",
       "      <td>-2.981218</td>\n",
       "      <td>disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32052</th>\n",
       "      <td>-2.602091</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132783</th>\n",
       "      <td>-2.563993</td>\n",
       "      <td>useless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61887</th>\n",
       "      <td>-2.510443</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122776</th>\n",
       "      <td>-2.472915</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94612</th>\n",
       "      <td>-2.435888</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94623</th>\n",
       "      <td>-2.413184</td>\n",
       "      <td>poorly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103792</th>\n",
       "      <td>-2.271653</td>\n",
       "      <td>returning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103769</th>\n",
       "      <td>-1.975957</td>\n",
       "      <td>returned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Coef          Words\n",
       "139538 -3.184703          worst\n",
       "39961  -2.981218  disappointing\n",
       "32052  -2.602091        concept\n",
       "132783 -2.563993        useless\n",
       "61887  -2.510443       horrible\n",
       "122776 -2.472915       terrible\n",
       "94612  -2.435888           poor\n",
       "94623  -2.413184         poorly\n",
       "103792 -2.271653      returning\n",
       "103769 -1.975957       returned"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_table.sort_values(by=\"Coef\").head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten most negative words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see not all the words are classified correctly, for egzample word \"worry\" in positive words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\n",
    "rating_pred = model.predict(review_test_V) # calculate ratings based on review using model creating by LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate ratings based on review using LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\n",
    "rating_pred_proba = model.predict_proba(review_test_V)\n",
    "\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:\n",
      " 116083    Ive had this stroller for a little more than s...\n",
      "21557     Ok I read all the reviews already posted here ...\n",
      "114796    My husband and I cannot state enough how much ...\n",
      "180953    AMAZING stroller  It took me about 2 minutes t...\n",
      "144112    Background Ive been using Grovia diapers for f...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Negative:\n",
      " 54418    THIS BASSINET IS OVERPRICED AND RIDICULOUS  If...\n",
      "16042    We have not had ANY luck with FisherPrice prod...\n",
      "59062    WARNING to all owners newer model Peg Perego S...\n",
      "87026    First off I did manage to find this product fo...\n",
      "10180    Please see my email to the companyHelloI am wr...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#c) \n",
    "indexes_P = np.argsort(rating_pred_proba[:,1])[-5:]\n",
    "print(\"Positive:\\n\", review_test.iloc[indexes_P])\n",
    "\n",
    "indexes_N = np.argsort(rating_pred_proba[:,0])[-5:]\n",
    "print(\"\\nNegative:\\n\", review_test.iloc[indexes_N])\n",
    "\n",
    "#hint: use the results of b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of predictions: 0.9308159756926399\n"
     ]
    }
   ],
   "source": [
    "#d) \n",
    "acc = sum(rating_pred==rating_test)/len(rating_test)\n",
    "print(\"Accuracy of predictions:\", acc)\n",
    "time1 = time.time() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\n",
    "start2= time.time()\n",
    "\n",
    "X_trainSW, X_testSW, y_trainSW, y_testSW = train_test_split(baby_df.review,baby_df.rating, test_size=0.3, random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive:\n",
      " 90795     This diaper bag is PERFECT There are a lot of ...\n",
      "181875    There is probably nothing more scrutinized the...\n",
      "174637    Over the last five years I have tried many dif...\n",
      "103297    I was very excited when I heard Chicco was fin...\n",
      "12035     My daughter 8 months old loves this toy and ha...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Negative:\n",
      " 56798     I was excited to give these instruments to my ...\n",
      "35763     Day 1 Assembled it Had it up and running playi...\n",
      "140418    I am a researchaholic in general and have rese...\n",
      "119175    Babyhaven knew that the items were never taken...\n",
      "22491     My wife has been sucessful using the pump but ...\n",
      "Name: review, dtype: object\n",
      "\n",
      "Accuracy of predictions: 0.8682285211689921\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(significant_words)\n",
    "\n",
    "X_trainSW_V = vectorizer.transform(X_trainSW.values)\n",
    "X_testSW_V = vectorizer.transform(X_testSW.values)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_trainSW_V, y_trainSW)\n",
    "\n",
    "coefs = model.coef_[0]\n",
    "d = {\"Coef\": coefs, \"Names\": vectorizer.get_feature_names()}\n",
    "words_table = pd.DataFrame(d)\n",
    "\n",
    "y_predSW = model.predict(X_testSW_V)\n",
    "y_pred_probaSW = model.predict_proba(X_testSW_V)\n",
    "\n",
    "indexes_P = np .argsort(y_pred_probaSW[:,1])[-5:]\n",
    "print(\"Positive:\\n\", X_testSW.iloc[indexes_P])\n",
    "\n",
    "indexes_N = np.argsort(y_pred_probaSW[:,0])[-5:]\n",
    "print(\"\\nNegative:\\n\", X_testSW.iloc[indexes_N])\n",
    "\n",
    "acc2 = sum(y_predSW==y_testSW)/len(y_testSW)\n",
    "print(\"\\nAccuracy of predictions:\", acc2)\n",
    "time2 = time.time() - start2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time without limited dictionary  53.57116198539734\n",
      "Time with limited dictionary  15.101290941238403\n",
      "Accuracy of predictions without limited dictionary  0.9308159756926399\n",
      "Accuracy of predictions with limited dictionary  0.8682285211689921\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "\n",
    "print(\"Time without limited dictionary \", time1)\n",
    "print(\"Time with limited dictionary \", time2)\n",
    "print(\"Accuracy of predictions without limited dictionary \", acc)\n",
    "print(\"Accuracy of predictions with limited dictionary \", acc2)\n",
    "\n",
    "#hint: %time, %timeit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that limited dictionary improves time significantly, but slightly decreases accuracy."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 10 2022, 12:46:26) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
